////
This guide is maintained in the main Quarkus repository
and pull requests should be submitted there:
https://github.com/quarkusio/quarkus/tree/main/docs/src/main/asciidoc
////
[id="deploying-to-openshift"]
= Deploying {project-name} applications to {openshift}
include::_attributes.adoc[]
:categories: cloud, native
:summary: This guide describes the deployment of {project-name} applications to {openshift}.
:numbered:
:sectnums:
:sectnumlevels: 4
:topics: devops,kubernetes,openshift,cloud,deployment
:extensions: io.quarkus:quarkus-openshift

{openshift-long} is a Kubernetes-based platform for developing and running containerized applications.
Quarkus offers the ability to automatically generate {openshift} resources based on sane defaults and user-supplied configuration.

As an application developer, you can deploy your {project-name} applications to {openshift-long}.
This functionality is provided by the `quarkus-openshift` extension, which supports multiple deployment options:

* xref:deploying-to-openshift-howto.adoc[With a single step]
* xref:deploying-to-openshift-docker-howto.adoc[By using a Docker build strategy]
* xref:deploying-to-openshift-s2i-howto.adoc[By using a Source-to-Image (S2I) strategy]
* xref:deploying-to-openshift-native-howto.adoc[Compiled to native executables]

== Overview of {openshift} build strategies

Docker build:: This strategy builds the artifacts outside the {openshift} cluster, locally or in a CI environment, and provides them to the {openshift} build system together with a Dockerfile.
The artifacts include JAR files or a native executable.
The container gets built inside the {openshift} cluster and is provided as an image stream.

[NOTE]
====
The {openshift} Docker build strategy is the preferred build strategy because it supports Quarkus applications targeted for JVM or compiled to native executables.
However, for compatibility with earlier Quarkus versions, the default build strategy is S2I.
To select the {openshift} Docker build strategy, use the `quarkus.openshift.build-strategy` property.
====

Source to Image (S2I):: The build process is performed inside the {openshift} cluster.
{project-name} fully supports using S2I to deploy {project-name} as a JVM application.

Binary S2I:: This strategy uses a JAR file as input to the S2I build process, which speeds up the building and deploying of your application.

=== Build strategies supported by Quarkus

The following table outlines the build strategies that {project-name} supports:

[cols="15%,15%,15%,15%,15%,15%",options="header"]
|====
|Build strategy| Support for {project-name} tools|Support for JVM | Support for native | Support for JVM Serverless | Support for native Serverless
|Docker build | YES | YES| YES| YES | YES
|S2I Binary| YES | YES | NO| NO | NO
|Source S2I | NO | YES| NO | NO | NO
|====

== Bootstrapping the project

First, you need a new project that contains the OpenShift extension.
Then, before you build and deploy your application, you must log into an OpenShift cluster.

=== Adding the OpenShift extension

To build and deploy your applications as a container image that runs inside your {openshift} cluster, you must add the {project-name} OpenShift extension `quarkus-openshift` as a dependency to your project.

This extension also generates {openshift} resources such as image streams, build configuration, deployment, and service definitions.
If your application includes the `quarkus-smallrye-health` extension, {openshift} can access the health endpoint and verify the startup, liveness, and readiness of your application.

[IMPORTANT]
====
From {project-name} 3.8, the `DeploymentConfig` object, deprecated in OpenShift, is also deprecated in {project-name}.
`Deployment` is the default and preferred deployment kind for the `quarkus-openshift` extension.
If you redeploy applications that you deployed before by using `DeploymentConfig`, by default, those applications use `Deployment` but do not remove the previous `DeploymentConfig`.
This leads to a deployment of both new and old applications, so, you must remove the old `DeploymentConfig` manually.
However, if you want to continue to use `DeploymentConfig`, it is still possible to do so by explicitly setting `quarkus.openshift.deployment-kind` to `DeploymentConfig`.
====

.Prerequisites

* You have a Quarkus Maven project.

.Procedure

. To add the `quarkus-openshift` extension to your project, use one of the following methods:
* Configure the `pom.xml` file:
+
.pom.xml
[source,xml,subs="+quotes,attributes+"]
----
<dependency>
    <groupId>io.quarkus</groupId>
    <artifactId>quarkus-openshift</artifactId>
</dependency>
----
* Enter the following command on the {openshift} CLI:
+
[source,bash,subs="+quotes,attributes+"]
----
./mvnw quarkus:add-extension -Dextensions="io.quarkus:quarkus-openshift"
----
+
* Enter the following command on the Quarkus CLI:
+
[source,bash,subs="+quotes,attributes+"]
----
quarkus extension add quarkus-openshift
----

== Logging in to an {openshift} cluster

You can log in to an {openshift} cluster by using the OpenShift CLI (`oc`).
For more information, see link:https://docs.openshift.com/container-platform/4.18/cli_reference/openshift_cli/getting-started-cli.html[Getting started with the OpenShift CLI]:

.Example: Log in by using the OpenShift CLI
[source,bash]
----
oc login -u myUsername <1>
----
<1> You are prompted for the required information such as server URL, password, and so on.

Alternatively, you can log in by using the API token:

.Example: Log in by using the OpenShift CLI with API token
[source,bash]
----
oc login --token=myToken --server=myServerUrl
----

TIP: You can request the token by using the _Copy Login Command_ link in the OpenShift web console.

Finally, you do not need to use the OpenShift CLI at all.
Instead, set the `quarkus.kubernetes-client.api-server-url` config property and authenticate with the `quarkus.kubernetes-client.token`, or `quarkus.kubernetes-client.username` and `quarkus.kubernetes-client.password` respectively:

:build-additional-parameters: -Dquarkus.kubernetes-client.api-server-url=myServerUrl -Dquarkus.kubernetes-client.token=myToken
include::{includes}/devtools/build.adoc[]
:!build-additional-parameters:

=== Switching to the required {openshift} project

You can use the {openshift-long} CLI to create applications and manage your {openshift} projects.
Use the information provided to create an {openshift} project or to switch to an existing one.

.Prerequisites

* You have access to an {openshift} cluster and the latest compatible version of the `oc` tool installed.

.Procedure

. Log in to the `oc` tool:
+
[source,shell]
----
oc login
----
. To show the current project space, enter the following command:
+
[source,shell]
----
oc project -q
----
. Use one of the following steps to go to the required {openshift} project:
.. If the project already exists, switch to the project:
+
[source,shell]
----
oc project <project_name>
----
+
.. If the project does not exist, create a new project:
+
[source,shell]
----
oc new-project <project_name>
----

== Building and deploying

You can build and deploy by using any of the following deployment options:

* xref:deploying-to-openshift-howto.adoc[With a single step]
* xref:deploying-to-openshift-docker-howto.adoc[By using a Docker build strategy]
* xref:deploying-to-openshift-S2I-howto.adoc[By using a Source-to-Image (S2I) strategy]
* xref:deploying-to-openshift-native-howto.adoc[Compiled to native executables]

ifndef::no-configuring-application-manually[]
=== Configuring the OpenShift application manually

If you need more control over the deployment configuration, you can build the container image first and then configure the OpenShift application manually.

To trigger a container image build:

[source,bash,subs=attributes+]
----
./mvnw clean package -Dquarkus.container-image.build=true
----

The build that is performed is a _s2i binary_ build.
The input of the build is the JAR file that has been built locally and the build output is an `ImageStream` that is configured to automatically trigger a deployment.
The base or builder image is specified by using `base-jvm-image` and `base-native-image` for JVM and native mode respectively.
An `ImageStream` for the image is automatically generated, unless these properties are used to reference an existing `ImageStreamTag` in the internal openshift registry.
For example:

[source,properties]
----
quarkus.openshift.base-jvm-image=image-registry.openshift-image-registry.svc:5000/some-project/openjdk-11:17.1.16.
----

[NOTE]
====
During the build you might find the `Caused by: javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: PKIX path building failed` exception due to self-signed certificate.
To solve this, add the following line to your `application.properties` file:
[source,properties]
----
quarkus.kubernetes-client.trust-certs=true
----
For more information, see xref:deploying-to-kubernetes.adoc#client-connection-configuration[deploying to Kubernetes].
====

After the build is finished, you can create a new application from the relevant `ImageStream`.

[source,bash,subs=attributes+]
----
oc get is <1>
oc new-app --name=greeting <project>/openshift-quickstart:1.0.0-SNAPSHOT <2>
oc get svc
oc expose svc/greeting <3>
oc get routes <4>
curl http://<route>/hello <5>
----
<1> Lists the image streams created.
The image stream of our application should be tagged as <project>/openshift-quickstart:1.0.0-SNAPSHOT.
<2> Create a new application from the image source.
<3> Expose the service to the outside world.
<4> Get the list of exposed routes.
<5> Access your application.

After this setup the next time the container image is built a deployment to OpenShift is triggered automatically.
In other words, you do not need to repeat the above steps.
endif::no-configuring-application-manually[]

=== Non-S2I builds

The OpenShift extension is configured to use xref:container-image.adoc#s2i[container-image-s2i]. However, it is still possible to use other container image extensions, such as:

- xref:container-image.adoc#docker[container-image-docker]
- xref:container-image.adoc#jib[container-image-jib]

When a non-s2i container image extension is used, an `ImageStream` is created that is pointing to an external `dockerImageRepository`. The image is built and pushed to the registry and the `ImageStream` populates the tags that are available in the `dockerImageRepository`.

To select which extension will be used for building the image:

[source,properties]
----
quarkus.container-image.builder=docker
----

or

[source,properties]
----
quarkus.container-image.builder=jib
----

== Customizing

All available customization options are available in the xref:deploying-to-kubernetes.adoc#openshift[OpenShift configuration options].

Some examples are provided in the sections below:

[[exposing_routes]]
=== Exposing routes

To expose a `Route` for the Quarkus application:

[source,properties]
----
quarkus.openshift.route.expose=true
----

[TIP]
====
You do not need to add this property in the `application.properties` file.
Instead, you can pass it as a command-line argument:
[source,bash,subs=attributes+]
----
./mvnw clean package -Dquarkus.openshift.route.expose=true
----
The same applies to all properties listed below.
====

==== Securing the Route resource

To secure the incoming connections, OpenShift provides several types of TLS termination to serve certifications.

For more information about how to secure routes, see https://docs.openshift.com/container-platform/4.18/networking/routes/secured-routes.html[OpenShift Container Platform] documentation.

The following example shows how to configure a secured Route by using passthrough termination by adding the "quarkus.openshift.route.tls" properties:

[source,properties]
----
quarkus.openshift.route.expose=true
quarkus.openshift.route.target-port=https
## Route TLS configuration:
quarkus.openshift.route.tls.termination=passthrough
quarkus.openshift.route.tls.insecure-edge-termination-policy=None
----

=== Labels

To add a label in the generated resources:

[source,properties]
----
quarkus.openshift.labels.foo=bar
----

=== Annotations

To add an annotation in the generated resources:

[source,properties]
----
quarkus.openshift.annotations.foo=bar
----

[[env-vars]]
=== Environment variables

{openshift} provides multiple ways of defining environment variables:

- Key/value pairs
- Import all values from a Secret or ConfigMap
- Interpolate a single value identified by a given field in a Secret or ConfigMap
- Interpolate a value from a field within the same resource

==== Environment variables from key/value pairs

To add a key/value pair as an environment variable in the generated resources:

[source,properties]
----
quarkus.openshift.env.vars.my-env-var=foobar
----

The above command adds `MY_ENV_VAR=foobar` as an environment variable.
The key `my-env-var` will convert to uppercase and dashes will be replaced by underscores resulting in `MY_ENV_VAR`.

==== Environment variables from Secret

To add all key/value pairs of `Secret` as environment variables, apply the following configuration, separating each `Secret` to be used as source by a comma (`,`):

[source,properties]
----
quarkus.openshift.env.secrets=my-secret,my-other-secret
----

which generates the following in the container definition:

[source,yaml]
----
envFrom:
  - secretRef:
      name: my-secret
      optional: false
  - secretRef:
      name: my-other-secret
      optional: false
----

The following code extracts a value identified by the `keyName` field from the `my-secret` Secret into a `foo` environment variable:

[source,properties]
----
quarkus.openshift.env.mapping.foo.from-secret=my-secret
quarkus.openshift.env.mapping.foo.with-key=keyName
----

which generates the following in the `env` section of your container:

[source,yaml]
----
- env:
  - name: FOO
    valueFrom:
      secretKeyRef:
        key: keyName
        name: my-secret
        optional: false
----

==== Environment variables from ConfigMap

To add all key/value pairs from `ConfigMap` as environment variables, apply the following configuration, separating each `ConfigMap` to be used as source by a comma (`,`):

[source,properties]
----
quarkus.openshift.env.configmaps=my-config-map,another-config-map
----

which generates the following in the container definition:

[source,yaml]
----
envFrom:
  - configMapRef:
      name: my-config-map
      optional: false
  - configMapRef:
      name: another-config-map
      optional: false
----

The following extracts a value identified by the `keyName` field from the `my-config-map` ConfigMap into a `foo` environment variable:

[source,properties]
----
quarkus.openshift.env.mapping.foo.from-configmap=my-configmap
quarkus.openshift.env.mapping.foo.with-key=keyName
----

which generates the following in the `env` section of your container:

[source,yaml]
----
- env:
  - name: FOO
    valueFrom:
      configMapKeyRef:
        key: keyName
        name: my-configmap
        optional: false
----

==== Environment variables from fields

You can also use the value from another field to add a new environment variable by specifying the path of the field to be used as a source.
For example:

[source,properties]
----
quarkus.openshift.env.fields.foo=metadata.name
----

==== Changing the generated deployment resource

Beside generating a `Deployment` resource, you can also choose to get either a `DeploymentConfig`, `StatefulSet`, `Job`, or a `CronJob` resource instead by using `application.properties`:

[source,properties]
----
quarkus.openshift.deployment-kind=StatefulSet
----

===== Generating Job resources

If you want to generate a Job resource, you need to add the following property by using the `application.properties`:

[source,properties]
----
quarkus.openshift.deployment-kind=Job
----

IMPORTANT: If you are using the Picocli extension, by default the Job resource will be generated.

You can provide the arguments that Kubernetes Job uses through the `quarkus.openshift.arguments` property.
For example, adding the property `quarkus.openshift.arguments=A,B`.

Finally, the Kubernetes job will be launched every time that it is installed in OpenShift.
For more information about how to run Kubernetes jobs, see https://kubernetes.io/docs/concepts/workloads/controllers/job/#running-an-example-job[Running an example job].

You can configure the rest of the Kubernetes Job configuration by using the properties under `quarkus.openshift.job.xxx`.
For more information, see xref:deploying-to-openshift.adoc#quarkus-kubernetes_quarkus-openshift-job-parallelism[quarkus.openshift.job.parallelism].

===== Generating CronJob resources

If you want to generate a CronJob resource, you need to add the following property by using the `application.properties` file:

[source,properties]
----
quarkus.openshift.deployment-kind=CronJob
# Cron expression to run the job every hour
quarkus.openshift.cron-job.schedule=0 * * * *
----

IMPORTANT: CronJob resources require the https://en.wikipedia.org/wiki/Cron[Cron] expression to specify when to launch the job through the `quarkus.openshift.cron-job.schedule` property.
If they are not provided, the build fails.

You can configure the rest of the Kubernetes CronJob configuration by using the properties under `quarkus.openshift.cron-job.xxx` (for more information, see xref:deploying-to-openshift.adoc#quarkus-kubernetes_quarkus-openshift-cron-job-parallelism[quarkus.openshift.cron-job.parallelism]).

==== Validation

A conflict between two definitions, for example, mistakenly assigning both a value and specifying that a variable is derived from a field, results in an error being thrown at build time.
You can fix the issue before you deploy your application to your cluster, where it might be more difficult to diagnose the source of the issue.

Similarly, two redundant definitions, for example, defining an injection from the same secret twice, does not cause an issue but reports a warning to inform you that you might not have intended to duplicate that definition.

[[env-vars-backwards]]
===== Backwards compatibility

Previous versions of the OpenShift extension supported a different syntax to add environment variables.
The older syntax is still supported but is deprecated, and it is advised that you migrate to the new syntax.

.Old syntax versus new syntax
|====
|                               |Old                                                    | New                                                 |
| Plain variable                |`quarkus.openshift.env-vars.my-env-var.value=foobar`  | `quarkus.openshift.env.vars.my-env-var=foobar`     |
| From field                    |`quarkus.openshift.env-vars.my-env-var.field=foobar`  | `quarkus.openshift.env.fields.my-env-var=foobar`   |
| All from `ConfigMap`          |`quarkus.openshift.env-vars.xxx.configmap=foobar`     | `quarkus.openshift.env.configmaps=foobar`          |
| All from `Secret`             |`quarkus.openshift.env-vars.xxx.secret=foobar`        | `quarkus.openshift.env.secrets=foobar`             |
| From one `Secret` field       |`quarkus.openshift.env-vars.foo.secret=foobar`        | `quarkus.openshift.env.mapping.foo.from-secret=foobar` |
|                               |`quarkus.openshift.env-vars.foo.value=field`          | `quarkus.openshift.env.mapping.foo.with-key=field` |
| From one `ConfigMap` field    |`quarkus.openshift.env-vars.foo.configmap=foobar`     | `quarkus.openshift.env.mapping.foo.from-configmap=foobar` |
|                               |`quarkus.openshift.env-vars.foo.value=field`          | `quarkus.openshift.env.mapping.foo.with-key=field` |
|====

[NOTE]
====
 If you redefine the same variable by using the new syntax while keeping the old syntax, only the new version is kept, and a warning will be issued to alert you of the problem.
 For example, if you define both `quarkus.openshift.env-vars.my-env-var.value=foobar` and `quarkus.openshift.env.vars.my-env-var=newValue`, the extension generates an environment variable `MY_ENV_VAR=newValue` and issues a warning.
====

=== Mounting volumes

The OpenShift extension allows you to configure both volumes and mounts for the application.
You can mount any volume with a simple configuration:

[source,properties]
----
quarkus.openshift.mounts.my-volume.path=/where/to/mount
----

This will add a mount to my pod for volume `my-volume` to path `/where/to/mount`.
You can configure the volumes themselves as shown in the sections below:

==== Secret volumes

[source,properties]
----
quarkus.openshift.secret-volumes.my-volume.secret-name=my-secret
----

==== ConfigMap volumes

[source,properties]
----
quarkus.openshift.config-map-volumes.my-volume.config-map-name=my-config-map
----

==== Persistent volume claims

[source,properties]
----
quarkus.openshift.pvc-volumes.my-pvc.claim-name=my-pvc
----

ifndef::no-knative-serverless-deployment[]
== Knative - OpenShift Serverless

OpenShift also provides the ability to use Knative by using the link:https://www.openshift.com/learn/topics/serverless[OpenShift Serverless] functionality.

First, you instruct Quarkus to generate Knative resources:

[source,properties]
----
quarkus.kubernetes.deployment-target=knative
----

To leverage OpenShift S2I to build the container image on the cluster and use the resulting container image for the Knative application, set the following configuration properties:

[source,properties]
----
# set the Kubernetes namespace which will be used to run the application
quarkus.container-image.group=geoand
# set the container image registry - this is the standard URL used to refer to the internal OpenShift registry
quarkus.container-image.registry=image-registry.openshift-image-registry.svc:5000
----

You can then deploy the application to OpenShift Serverless by enabling the standard `quarkus.kubernetes.deploy=true` property.
endif::no-knative-serverless-deployment[]

== Configuration Reference

include::{generated-dir}/config/quarkus-kubernetes_quarkus.openshift.adoc[opts=optional, leveloffset=+1]
