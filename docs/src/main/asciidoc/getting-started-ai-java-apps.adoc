////
This document is maintained in the main Quarkus repository
and pull requests should be submitted there:
https://github.com/quarkusio/quarkus/tree/main/docs/src/main/asciidoc
////
////
TODO:
- Title: https://quarkus.io/guides/doc-reference#titles-headings
- Use the file name as the ID
- Choose appropriate categories: https://quarkus.io/guides/doc-reference#categories
////
[id="getting-started-ai-java-apps"]
= Creating your first AI Java application using LangChain4j
include::_attributes.adoc[]
:quickstart-includes: https://github.com/lauracowen/quarkus-quickstarts/getting-started-ai-java-apps/main
:diataxis-type: tutorial
:categories: getting-started, ai
////
:extension-status: preview
TODO: uncomment the above for experimental or tech-preview content.
The document header ends at the first blank line. Do not remove the blank line between the header and the abstract summary.
////

Create a simple RESTful Java AI application that asks a large language model (LLM, or genAI) to write a short poem based on a topic provided by the user. The service responds to GET requests made to the `http://localhost:8080/poems/{my-topic}/{my-lines}` URL. The user enters the topic and length of the desired poem; for example `http://localhost:8080/poems/purple/5`, to generate a poem such as:

----
In velvet skies, the stars do dance,
A million whispers, a cosmic romance.
They weave tales of old, in shimmering light,
Guiding lost souls through the velvet night.
In their glow, the universe finds its chance.
----

You will create a Java class and a Java interface. The class represents a resource which defines the application's endpoint and calls the AI model by using the interface to implement an AI service. The AI service uses the parameter values passed in through the endpoint to build a prompt, a natural language text request, and sends it to the AI.

The AI (the large language model, or LLM) parses the prompt and returns a poem according to the topic and number of lines requested in the prompt. LLMs are AI models that are trained to generate output based on the natural language requests they receive. The input and output of LLMs are usually text, as in this application, but some LLMs specialise in other formats such as images or video.

Much of the work needed to build the prompt and to connect to the LLM in order to send the request and get a response is handled for you by LangChain4j, an open source extension to Quarkus.

image::xxxx.png[alt=Architecture, align=center]
// TODO: Create diagram.



// TODO: If this is a tutorial for an experimental or tech-preview extension, uncomment the following (otherwise delete)
include::{includes}/extension-status.adoc[]


== Prerequisites

:prerequisites-no-graalvm:
include::{includes}/prerequisites.adoc[]

For this guide, the application is so simple that we can use a demo key for OpenAI.

== Solution

Follow the instructions in this guide to create the application.

However, you can first run the completed example to see how it works:

1. Download an {quickstarts-archive-url}[archive] or clone the git repository:
+
[source,bash,subs=attributes+]
----
git clone {quickstarts-clone-url}
----
+
The solution is located in the `xxx` link:{quickstarts-tree-url}/getting-started-ai-java-apps[directory].

:sectnums:
:sectnumlevels: 1

== Creating the project

The easiest way to create a new Quarkus project is to open a terminal and run the following command:

:create-app-artifact-id: getting-started-ai-java-apps
:create-app-extensions: rest
:create-app-code:
include::{includes}/devtools/create-app.adoc[]

It generates the following items in `./getting-started`:

* the Maven structure
* an `org.acme.GreetingResource` resource exposed on `/hello`
* an associated unit test
* a landing page that is accessible on `http://localhost:8080` after starting the application
* example `Dockerfile` files for both `native` and `jvm` modes in `src/main/docker`
* the application configuration file

[[ai-service]]
== Creating the AI service

The AI service provides an abstraction layer to make it easier to write a Java application that interacts with an LLM. The AI service builds the prompts to send to the LLM and receives the responses from the LLM on behalf of the application. The application needs only minimal configuration to connect to the LLM because the AI service handles the connection details. AI services can manage other information too, including chat memory and toolboxes, which will be explored in other guides.

The AI service builds the prompt from two pieces of information in the class that implements the AI service:

- the System message, which provides the context of the prompt. The System message can include examples of the response generated by the LLM.
- the User message, which provides the question that the application user is asking the LLM. The user message is usually received, and processed, by the LLM after the System message.

Create the `AiPoemService.java` interface:

[source,java,linenums]
----
package org.acme;

import dev.langchain4j.service.SystemMessage;
import dev.langchain4j.service.UserMessage;
import io.quarkiverse.langchain4j.RegisterAiService;

@RegisterAiService( ) // <1>
public interface AiPoemService {

    @SystemMessage("You are a professional poet. Display the poem in well-formed HTML with line breaks (no markdown).") // <2>
    @UserMessage("""
                Write a poem about {topic}. The poem should be {lines} lines long. // <3>
            """)
    String writeAPoem(String topic, int lines); // <4>
}

----
<1> Implements the interface as an AI service which can connect to the LLM that is configured in the `resources/application.properties` file.
<2> The system message instructs the LLM to take the role of a professional poet and to display the generated poem in well-formed HTML with line breaks so that it renders neatly when viewed in a web browser. This application is so simple that an example response is not necessary.
<3> The user message asks the LLM to generate a poem on the topic and of the length that the user has chosen. The user's choices are passed as parameters from the endpoint, `{my-topic}` and `{my-lines}`, to complete the templated User message placeholders, `{topic}` and `{lines}`.
<4> Starts an exchange between the application and the LLM, sending the system message and then the user message. The `writeAPoem()` method is called by the `showMeAPoem()` method in the Poems class, passing in the user's chosen topic and length from the endpoint parameters.

[[rest-resource]]
== Creating the RESTful resource

The RESTful resource defines the endpoint of your RESTful service. When a GET request is made to the endpoint, the `showMeAPoem()` method runs and calls the `writeAPoem()` method in the AI service to send a request to the LLM.

In this application, the resource class defines the endpoint that receives the user's input (choice of topic and number of lines in the poem) and then passes it to the AI service to include in its request to the LLM.

Create the `Poems.java` class:

[source,java,linenums]
----
package org.acme;

import jakarta.inject.Inject;
import jakarta.ws.rs.GET;
import jakarta.ws.rs.Path;
import jakarta.ws.rs.PathParam;
import jakarta.ws.rs.Produces;
import jakarta.ws.rs.core.MediaType;

@Path("/poems")
public class Poems {

    @Inject
    AiPoemService aiPoemService;  //<1>

    @GET
    @Produces(MediaType.TEXT_HTML)
    @Path("/{my-topic}/{my-lines}")  //<2>
    public String showMeAPoem(@PathParam("my-topic") String requestedTopic, @PathParam("my-lines") int requestedLines) {  //<3>
        return aiPoemService.writeAPoem(requestedTopic, requestedLines);  // <4>
    }
}

----
<1> Implements the AiPoemService interface as aiPoemService.
<2> Defines the RESTful endpoint that takes the user's input as endpoint parameters, `{my-topic}` and `{my-lines}`.
<3> Declares the `showMeAPoem()` method which takes two arguments, `requestedTopic` and `requestedLines` (because there is more than one argument, you must explicitly annotate each parameter). When a GET request is made to the `/poems/{my-topic}/{my-lines}` endpoint, the values of the `{my-topic}` and `{my-lines}` parameters are passed as the `writeAPoem()` method's `requestedTopic` and `requestedLines` arguments.
<4> The `showMeAPoem()` method calls the AI service's `writeAPoem()` method with the values received from the endpoint. Calling the `writeAPoem()` method causes these values to be added to the user message as part of the prompt that the AI service sends to the LLM. The response from the LLM is then displayed in HTML.

[[configure]]
== Configuring the application

Connecting to an LLM is greatly simplified by using LangChain4j. For this application, Quarkus uses the link:https://quarkus.io/extensions/io.quarkiverse.langchain4j/quarkus-langchain4j-openai/[Quarkus LangChain4j OpenAI extension], which is configured in the `pom.xml`. You then need only set the API key and the base URL properties for the LLM; in this case, you can use the value `demo` to get limited demo access to the LLM which is sufficient for this application:

[source,linenums]
----
quarkus.langchain4j.openai.api-key=demo
quarkus.langchain4j.openai.base-url=http://langchain4j.dev/demo/openai/v1
----

[[run]]
== Running the application

If you have link:https://quarkus.io/get-started/[installed the Quarkus CLI (see Step 1)], run the following command to start Quarkus in dev mode:

----
quarkus dev
----

Otherwise, run the following Maven command which starts the application in dev mode:

----
./mvnw quarkus:dev
----

Any changes you make to the application are automatically rebuilt and re-deployed while running in dev mode.

To test the application, request the endpoint with the values you choose replacing the template placeholders. For example, request a poem of 5 lines about purple with the URI `http://localhost:8080/poems/purple/5`. The HTML request in the system message means that it should display neatly in a web browser.

Alternatively, run the following curl command:

----
curl -w "\n" http://localhost:8080/poems/purple/5
----

Notice that there is a slight pause while the LLM responds, but then the application returns a short poem on the chosen topic and of the requested length.

:sectnums!:
== Where next?

Congratulations! You have created your first AI Java application and run it on Quarkus with LangChain4j. 

Next, if you want to learn more about writing AI Java applications with Quarkus and LangChain4j, take a look at the link:https://redhat-developer-demos.github.io/quarkus-tutorial/quarkus-tutorial/17_ai_intro.html[Quarkus and AI tutorial].
