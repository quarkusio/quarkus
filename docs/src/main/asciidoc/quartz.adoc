////
This guide is maintained in the main Quarkus repository
and pull requests should be submitted there:
https://github.com/quarkusio/quarkus/tree/main/docs/src/main/asciidoc
////
= Scheduling Periodic Tasks with Quartz

include::./attributes.adoc[]
:extension-status: preview

Modern applications often need to run specific tasks periodically.
In this guide, you learn how to schedule periodic clustered tasks using the http://www.quartz-scheduler.org/[Quartz] extension.

include::{includes}/extension-status.adoc[]

TIP: If you only need to run in-memory scheduler use the xref:scheduler.adoc[Scheduler] extension.

== Prerequisites

:prerequisites-docker-compose:
include::{includes}/prerequisites.adoc[]

== Architecture

In this guide, we are going to expose one Rest API `tasks` to visualise the list of tasks created by a Quartz job running every 10 seconds.

== Solution

We recommend that you follow the instructions in the next sections and create the application step by step.
However, you can go right to the completed example.

Clone the Git repository: `git clone {quickstarts-clone-url}`, or download an {quickstarts-archive-url}[archive].

The solution is located in the `quartz-quickstart` {quickstarts-tree-url}/quartz-quickstart[directory].

== Creating the Maven project

First, we need a new project. Create a new project with the following command:

:create-app-artifact-id: quartz-quickstart
:create-app-extensions: resteasy-reactive-jackson,quartz,hibernate-orm-panache,flyway,jdbc-postgresql
include::{includes}/devtools/create-app.adoc[]

It generates:

* the Maven structure
* a landing page accessible on `http://localhost:8080`
* example `Dockerfile` files for both `native` and `jvm` modes
* the application configuration file

The Maven project also imports the Quarkus Quartz extension.

If you already have your Quarkus project configured, you can add the `quartz` extension
to your project by running the following command in your project base directory:

:add-extension-extensions: quartz
include::{includes}/devtools/extension-add.adoc[]

This will add the following to your build file:

[source,xml,role="primary asciidoc-tabs-target-sync-cli asciidoc-tabs-target-sync-maven"]
.pom.xml
----
<dependency>
    <groupId>io.quarkus</groupId>
    <artifactId>quarkus-quartz</artifactId>
</dependency>
----

[source,gradle,role="secondary asciidoc-tabs-target-sync-gradle"]
.build.gradle
----
implementation("io.quarkus:quarkus-quartz")
----

[TIP]
====
To use a JDBC store, the `quarkus-agroal` extension, which provides the datasource support, is also required.
====

== Creating the Task Entity

In the `org.acme.quartz` package, create the `Task` class, with the following content:

[source,java]
----
package org.acme.quartz;

import jakarta.persistence.Entity;
import java.time.Instant;
import jakarta.persistence.Table;

import io.quarkus.hibernate.orm.panache.PanacheEntity;

@Entity
@Table(name="TASKS")
public class Task extends PanacheEntity { <1>
    public Instant createdAt;

    public Task() {
        createdAt = Instant.now();
    }

    public Task(Instant time) {
        this.createdAt = time;
    }
}
----
<1> Declare the entity using xref:hibernate-orm-panache.adoc[Panache]

== Creating a scheduled job

In the `org.acme.quartz` package, create the `TaskBean` class, with the following content:

[source,java]
----
package org.acme.quartz;

import jakarta.enterprise.context.ApplicationScoped;

import jakarta.transaction.Transactional;

import io.quarkus.scheduler.Scheduled;

@ApplicationScoped <1>
public class TaskBean {

    @Transactional
    @Scheduled(every = "10s", identity = "task-job") <2>
    void schedule() {
        Task task = new Task(); <3>
        task.persist(); <4>
    }
}
----
<1> Declare the bean in the _application_ scope
<2> Use the `@Scheduled` annotation to instruct Quarkus to run this method every 10 seconds and set the unique identifier for this job.
<3> Create a new `Task` with the current start time.
<4> Persist the task in database using xref:hibernate-orm-panache.adoc[Panache].

=== Scheduling Jobs Programmatically

It is also possible to leverage the Quartz API directly.
You can inject the underlying `org.quartz.Scheduler` in any bean:

[source,java]
----
package org.acme.quartz;

@ApplicationScoped
public class TaskBean {

    @Inject
    org.quartz.Scheduler quartz; <1>
    
    void onStart(@Observes StartupEvent event) throws SchedulerException {
       JobDetail job = JobBuilder.newJob(MyJob.class)
                         .withIdentity("myJob", "myGroup")
                         .build();
       Trigger trigger = TriggerBuilder.newTrigger()
                            .withIdentity("myTrigger", "myGroup")
                            .startNow()
                            .withSchedule(
                               SimpleScheduleBuilder.simpleSchedule()
                                  .withIntervalInSeconds(10)
                                  .repeatForever())
                            .build();
       quartz.scheduleJob(job, trigger); <2>
    }
    
    @Transactional
    void performTask() {
        Task task = new Task();
        task.persist();
    }
    
    // A new instance of MyJob is created by Quartz for every job execution
    public static class MyJob implements Job {

       @Inject
       TaskBean taskBean;
    
       public void execute(JobExecutionContext context) throws JobExecutionException {
          taskBean.performTask(); <3>
       }
    
    }
}
----
<1> Inject the underlying `org.quartz.Scheduler` instance.
<2> Schedule a new job using the Quartz API.
<3> Invoke the `TaskBean#performTask()` method from the job. Jobs are also xref:cdi.adoc[container-managed] beans if they belong to a link:cdi-reference[bean archive].

NOTE: By default, the scheduler is not started unless a `@Scheduled` business method is found. You may need to force the start of the scheduler for "pure" programmatic scheduling. See also <<quartz-configuration-reference>>.  

== Updating the application configuration file

Edit the `application.properties` file and add the below configuration:
[source,properties]
----
# Quartz configuration
quarkus.quartz.clustered=true <1>
quarkus.quartz.store-type=jdbc-cmt <2>
quarkus.quartz.misfire-policy.task-job=ignore-misfire-policy <3>

# Datasource configuration.
quarkus.datasource.db-kind=postgresql
quarkus.datasource.username=quarkus_test
quarkus.datasource.password=quarkus_test
quarkus.datasource.jdbc.url=jdbc:postgresql://localhost/quarkus_test

# Hibernate configuration
quarkus.hibernate-orm.database.generation=none
quarkus.hibernate-orm.log.sql=true
quarkus.hibernate-orm.sql-load-script=no-file

# flyway configuration
quarkus.flyway.connect-retries=10
quarkus.flyway.table=flyway_quarkus_history
quarkus.flyway.migrate-at-start=true
quarkus.flyway.baseline-on-migrate=true
quarkus.flyway.baseline-version=1.0
quarkus.flyway.baseline-description=Quartz
----
<1> Indicate that the scheduler will be run in clustered mode
<2> Use the database store to persist job related information so that they can be shared between nodes
<3> The misfire policy can be configured for each job. `task-job` is the identity of the job.

Valid misfire policy for cron jobs are: `smart-policy`, `ignore-misfire-policy`, `fire-now` and `cron-trigger-do-nothing`.
Valid misfire policy for interval jobs are: `smart-policy`, `ignore-misfire-policy`, `fire-now`, `simple-trigger-reschedule-now-with-existing-repeat-count`, `simple-trigger-reschedule-now-with-remaining-repeat-count`, `simple-trigger-reschedule-next-with-existing-count` and `simple-trigger-reschedule-next-with-remaining-count`.

== Creating a REST resource and a test

Create the `org.acme.quartz.TaskResource` class with the following content:

[source,java]
----
package org.acme.quartz;

import java.util.List;

import jakarta.ws.rs.GET;
import jakarta.ws.rs.Path;
import jakarta.ws.rs.Produces;
import jakarta.ws.rs.core.MediaType;

@Path("/tasks")
public class TaskResource {

    @GET
    public List<Task> listAll() {
        return Task.listAll(); <1>
    }
}
----
<1> Retrieve the list of created tasks from the database

You also have the option to create a `org.acme.quartz.TaskResourceTest` test with the following content:

[source,java]
----
package org.acme.quartz;

import io.quarkus.test.junit.QuarkusTest;

import static org.hamcrest.Matchers.greaterThanOrEqualTo;

import org.junit.jupiter.api.Test;

import static io.restassured.RestAssured.given;
import static org.hamcrest.CoreMatchers.is;

@QuarkusTest
public class TaskResourceTest {

    @Test
    public void tasks() throws InterruptedException {
        Thread.sleep(1000); // wait at least a second to have the first task created
        given()
                .when().get("/tasks")
                .then()
                .statusCode(200)
                .body("size()", is(greaterThanOrEqualTo(1))); <1>
    }
}
----
<1> Ensure that we have a `200` response and at least one task created

== Creating Quartz Tables

Add a SQL migration file named `src/main/resources/db/migration/V2.0.0\__QuarkusQuartzTasks.sql` with the content copied from
file with the content from link:{quickstarts-blob-url}/quartz-quickstart/src/main/resources/db/migration/V2.0.0__QuarkusQuartzTasks.sql[V2.0.0__QuarkusQuartzTasks.sql].

== Configuring the load balancer

In the root directory, create a `nginx.conf` file with the following content:

[source,conf]
----
user  nginx;

events {
    worker_connections   1000;
}

http {
        server {
              listen 8080;
              location / {
                proxy_pass http://tasks:8080; <1>
              }
        }
}
----
<1> Route all traffic to our tasks application

== Setting Application Deployment

In the root directory, create a `docker-compose.yml` file with the following content:

[source,yaml]
----
version: '3'

services:
  tasks: <1>
    image: quarkus-quickstarts/quartz:1.0
    build:
      context: ./
      dockerfile: src/main/docker/Dockerfile.${QUARKUS_MODE:-jvm}
    environment:
      QUARKUS_DATASOURCE_URL: jdbc:postgresql://postgres/quarkus_test
    networks:
      - tasks-network
    depends_on:
      - postgres

  nginx: <2>
    image: nginx:1.17.6
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - tasks
    ports:
      - 8080:8080
    networks:
      - tasks-network

  postgres: <3>
    image: postgres:14.1
    container_name: quarkus_test
    environment:
      - POSTGRES_USER=quarkus_test
      - POSTGRES_PASSWORD=quarkus_test
      - POSTGRES_DB=quarkus_test
    ports:
      - 5432:5432
    networks:
      - tasks-network

networks:
  tasks-network:
    driver: bridge
----
<1> Define the tasks service
<2> Define the nginx load balancer to route incoming traffic to an appropriate node
<3> Define the configuration to run the database

== Running the database

In a separate terminal, run the below command:

[source,bash]
----
docker-compose up postgres <1>
----
<1> Start the database instance using the configuration options supplied in the `docker-compose.yml` file

== Run the application in Dev Mode

Run the application with:

include::{includes}/devtools/dev.adoc[]

After a few seconds, open another terminal and run `curl localhost:8080/tasks` to verify that we have at least one task created.

As usual, the application can be packaged using:

include::{includes}/devtools/build.adoc[]

and executed with `java -jar target/quarkus-app/quarkus-run.jar`.

You can also generate the native executable with:

include::{includes}/devtools/build-native.adoc[]

== Packaging the application and run several instances

The application can be packaged using:

include::{includes}/devtools/build.adoc[]

Once the build is successful, run the below command:

[source,bash]
----
docker-compose up --scale tasks=2 --scale nginx=1 <1>
----
<1> Start two instances of the application and a load balancer

After a few seconds, in another terminal, run `curl localhost:8080/tasks` to verify that tasks were only created at different instants and in an interval of 10 seconds.

You can also generate the native executable with:

include::{includes}/devtools/build-native.adoc[]

WARNING: It's the responsibility of the deployer to clear/remove the previous state, i.e. stale jobs and triggers. Moreover, the applications that form the "Quartz cluster" should be identical, otherwise an unpredictable result may occur.

[[quartz-register-plugin-listeners]]
== Registering Plugin and Listeners

You can register `plugins`, `job-listeners` and `trigger-listeners` through Quarkus configuration.

The example below registers the plugin `org.quartz.plugins.history.LoggingJobHistoryPlugin` named as `jobHistory` with the property `jobSuccessMessage` defined as `Job [{1}.{0}] execution complete and reports: {8}`

[source,conf]
----
quarkus.quartz.plugins.jobHistory.class=org.quartz.plugins.history.LoggingJobHistoryPlugin
quarkus.quartz.plugins.jobHistory.properties.jobSuccessMessage=Job [{1}.{0}] execution complete and reports: {8}
----

You can also register a listener programmatically with an injected `org.quartz.Scheduler`:

[source,java]
----
public class MyListenerManager {
    void onStart(@Observes StartupEvent event, org.quartz.Scheduler scheduler) throws SchedulerException {
        scheduler.getListenerManager().addJobListener(new MyJogListener());
        scheduler.getListenerManager().addTriggerListener(new MyTriggerListener());
    }
}
----

[[quartz-configuration-reference]]
== Quartz Configuration Reference

include::{generated-dir}/config/quarkus-quartz.adoc[leveloffset=+1, opts=optional]
